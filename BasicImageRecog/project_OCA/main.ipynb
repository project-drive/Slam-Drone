{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import np_utils, print_summary\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "# imageSize= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2648, 65537)\n"
     ]
    }
   ],
   "source": [
    "totalnum_of_images = 2648\n",
    "datadir = \"/Users/sarveshbhatnagar/Desktop/AJIP/project_OCA\"\n",
    "categories = {0:\"fan_0\", 1:\"fan_1\", 2:\"fan_2\", 3:\"fan_3\"}\n",
    "counter = 0\n",
    "dataset = np.zeros(shape=(totalnum_of_images,65537))\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(datadir,categories[category])\n",
    "    label = np.array([category])\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            image = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (256,256))\n",
    "            te = image.flatten()\n",
    "            te = np.array(te)\n",
    "            te = np.concatenate((te, label), axis=0)\n",
    "            te = np.array(te)[np.newaxis]\n",
    "            #cv2.imwrite(\"newfan\"+str(i)+\".jpg\",image)\n",
    "            dataset[counter] = te\n",
    "            counter = counter + 1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([169., 169., 170., ..., 129., 129.,   0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(dataset)\n",
    "X = dataset\n",
    "Y = dataset\n",
    "#sclicing only the first 1023 columns so that we would get our features\n",
    "x = X[:, 0:65536]\n",
    "#sclicing the 1024th column which has the label for every record\n",
    "y = Y[:, 65536]\n",
    "#as the dataset is shuffled so selecting first 70K tuples won't harm\n",
    "x_train = x[0:2118, :]\n",
    "#diving by 255 makes it easier for learning data as now the value is in between 0 and 1(basically normalization)\n",
    "x_train = x_train/255\n",
    "\n",
    "x_test = x[2118:2648, :]\n",
    "#adjusting the shape of the matrices\n",
    "y = y.reshape(y.shape[0], 1)\n",
    "y_train = y[0:2118, :]\n",
    "y_train = y_train.T\n",
    "y_test = y[2118:2648, :]\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are taking an image of 32x32 for training purpose\n",
    "image_x = 256\n",
    "image_y = 256\n",
    "#to_categorical is an function which converts a matrix to a vector; in our case it basically gets the label which is an integer\n",
    "#and changes it to form of one_hot_encoding.\n",
    "#Check this link for more details->https://keras.io/utils/\n",
    "train_y = np_utils.to_categorical(y_train, dtype='int32')\n",
    "test_y = np_utils.to_categorical(y_test, dtype='int32')\n",
    "#adjusting the shape\n",
    "train_y = train_y.reshape(train_y.shape[1], train_y.shape[2])\n",
    "test_y = test_y.reshape(test_y.shape[1], test_y.shape[2])\n",
    "x_train = x_train.reshape(x_train.shape[0], image_x, image_y, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], image_x, image_y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explained in Readme file\n",
    "def keras_model(image_x, image_y):\n",
    "    num_of_classes = 4\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(10,10), input_shape=(image_x, image_y, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5,5), strides=(5,5), padding='same'))\n",
    "    model.add(Conv2D(64, (10,10), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5,5), strides=(5,5), padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #saving the trained data is saved here\n",
    "    filepath='OCA_1.h5'\n",
    "    checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint1]\n",
    "    #returning the model and the checkpoints of the saved(learned) data\n",
    "    return model, callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2118 samples, validate on 530 samples\n",
      "Epoch 1/10\n",
      "2118/2118 [==============================] - 281s 133ms/step - loss: 1.3095 - acc: 0.3942 - val_loss: 9.6359 - val_acc: 0.3962\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.39623, saving model to OCA_1.h5\n",
      "Epoch 2/10\n",
      "2118/2118 [==============================] - 269s 127ms/step - loss: 1.0161 - acc: 0.5732 - val_loss: 6.1373 - val_acc: 0.5906\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.39623 to 0.59057, saving model to OCA_1.h5\n",
      "Epoch 3/10\n",
      "2118/2118 [==============================] - 274s 129ms/step - loss: 0.7711 - acc: 0.6955 - val_loss: 5.5004 - val_acc: 0.6547\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.59057 to 0.65472, saving model to OCA_1.h5\n",
      "Epoch 4/10\n",
      "2118/2118 [==============================] - 1414s 668ms/step - loss: 0.5943 - acc: 0.7786 - val_loss: 6.0396 - val_acc: 0.6226\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.65472\n",
      "Epoch 5/10\n",
      "2118/2118 [==============================] - 273s 129ms/step - loss: 0.5149 - acc: 0.7932 - val_loss: 7.2651 - val_acc: 0.5358\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.65472\n",
      "Epoch 6/10\n",
      "2118/2118 [==============================] - 283s 134ms/step - loss: 0.4455 - acc: 0.8357 - val_loss: 6.5047 - val_acc: 0.5943\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.65472\n",
      "Epoch 7/10\n",
      "2118/2118 [==============================] - 270s 128ms/step - loss: 0.7308 - acc: 0.7054 - val_loss: 8.0857 - val_acc: 0.4887\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.65472\n",
      "Epoch 8/10\n",
      "2118/2118 [==============================] - 269s 127ms/step - loss: 0.4381 - acc: 0.8381 - val_loss: 6.3376 - val_acc: 0.6019\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.65472\n",
      "Epoch 9/10\n",
      "2118/2118 [==============================] - 315s 149ms/step - loss: 0.3444 - acc: 0.8659 - val_loss: 4.7862 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.65472 to 0.69811, saving model to OCA_1.h5\n",
      "Epoch 10/10\n",
      "2118/2118 [==============================] - 298s 141ms/step - loss: 0.2277 - acc: 0.9212 - val_loss: 6.3576 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.69811\n",
      "CNN error: 40.00%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 247, 247, 32)      3232      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 41, 41, 64)        204864    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 20740     \n",
      "=================================================================\n",
      "Total params: 228,836\n",
      "Trainable params: 228,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, callbacks_list = keras_model(image_x, image_y)\n",
    "model.fit(x_train, train_y, validation_data=(x_test, test_y), epochs=10, batch_size=64, callbacks=callbacks_list)\n",
    "scores = model.evaluate(x_test, test_y, verbose=0)\n",
    "print(\"CNN error: %.2f%%\" %(100 - scores[1] * 100))\n",
    "print_summary(model)\n",
    "model.save('OCA_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 29 variables.\n",
      "INFO:tensorflow:Converted 29 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pbmodel/my_model.pb'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in model.outputs])\n",
    "tf.train.write_graph(frozen_graph, \"pbmodel\", \"my_model.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
